{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Pip Install \"\"\"\n",
    "\n",
    "%pip install requests bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports \"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import unquote, urlparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Aux func \"\"\"\n",
    "\n",
    "def print_each(list_of_links):\n",
    "    \"\"\" print each \"\"\"\n",
    "    for link in list_of_links:\n",
    "        print(link)\n",
    "\n",
    "def print_size(list_of_links, link = ''):\n",
    "    \"\"\" print size \"\"\"\n",
    "    print('size:', '\\t', len(list_of_links), '\\t', link)\n",
    "\n",
    "def dedupe_and_sort(links):\n",
    "    \"\"\" filter and sort links \"\"\"\n",
    "    links = list(set(links)) # deduping\n",
    "    links.sort() # sorting\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected links once\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Scraping \"\"\"\n",
    "\n",
    "base_link = 'https://lgbtqia.fandom.com/wiki/'\n",
    "\n",
    "initial_links = ['', 'Special:AllPages', 'Special:AllPages?from=LGBTQA',\n",
    "         'Special:Categories', 'Category:Flags', 'Category:Stubs',]\n",
    "\n",
    "initial_links = [base_link + link for link in initial_links]\n",
    "\n",
    "allHyperLinks = {}\n",
    "\n",
    "def clean_found_hlinks(all_a):\n",
    "    \"\"\" clean found hyperlinks \"\"\"\n",
    "    current_hyperlinks = set()\n",
    "    for link in all_a:\n",
    "        got_href = link.get('href')\n",
    "        if got_href is not None:\n",
    "            got_href = got_href.lstrip('/')\n",
    "            got_href = got_href.lower()\n",
    "            full_link = got_href\n",
    "            if got_href.startswith('wiki/'):\n",
    "                full_link = 'https://lgbtqia.fandom.com/' + got_href\n",
    "            if full_link.startswith(base_link):\n",
    "                current_hyperlinks.add(full_link)\n",
    "    return current_hyperlinks\n",
    "\n",
    "def get_hyperlinks(url_soup):\n",
    "    \"\"\" get hyperlinks \"\"\"\n",
    "    all_a = url_soup.find_all('a')\n",
    "    cleaned_hlinks = clean_found_hlinks(all_a)\n",
    "    return cleaned_hlinks\n",
    "\n",
    "def get_soup(link):\n",
    "    \"\"\" parse link \"\"\"\n",
    "    page = requests.get(link)\n",
    "    if page.status_code != 200:\n",
    "        return None\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def process_all_website():\n",
    "    \"\"\" process all website \"\"\"\n",
    "    for link in initial_links:\n",
    "        soup = get_soup(link)\n",
    "        hyperlinks = get_hyperlinks(soup)\n",
    "        allHyperLinks[link] = {'soup': soup, 'hyperlinks': hyperlinks}\n",
    "\n",
    "process_all_website()\n",
    "\n",
    "print('collected links once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_processed_links = allHyperLinks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013\n",
      "processed/total: 58/968 https://lgbtqia.fandom.com/wiki/sexual_orientation\n",
      "processed/total: 59/973 https://lgbtqia.fandom.com/wiki/asexual_spectrum#fraysexual\n",
      "processed/total: 60/972 https://lgbtqia.fandom.com/wiki/cisgender?action=purge\n",
      "processed/total: 61/971 https://lgbtqia.fandom.com/wiki/file:panromantic_pride_flag.png\n",
      "processed/total: 62/977 https://lgbtqia.fandom.com/wiki/heteroqueer\n",
      "processed/total: 63/976 https://lgbtqia.fandom.com/wiki/file:labrys_lesbian_flag.svg\n",
      "processed/total: 64/979 https://lgbtqia.fandom.com/wiki/orbisian\n",
      "processed/total: 65/978 https://lgbtqia.fandom.com/wiki/file:genderfluid_flag.svg\n",
      "processed/total: 66/981 https://lgbtqia.fandom.com/wiki/genderf*ck\n",
      "processed/total: 67/980 https://lgbtqia.fandom.com/wiki/trixic\n",
      "processed/total: 68/979 https://lgbtqia.fandom.com/wiki/otter\n",
      "processed/total: 69/983 https://lgbtqia.fandom.com/wiki/polyamory\n",
      "processed/total: 70/994 https://lgbtqia.fandom.com/wiki/pulse_tragedy\n",
      "processed/total: 71/1021 https://lgbtqia.fandom.com/wiki/lesbian#lipstick_lesbian_flag_and_stripes\n",
      "processed/total: 72/1020 https://lgbtqia.fandom.com/wiki/file:demigirl_flag.svg\n",
      "processed/total: 73/1026 https://lgbtqia.fandom.com/wiki/desinoromantic\n",
      "processed/total: 74/1025 https://lgbtqia.fandom.com/wiki/aromantic_spectrum\n",
      "processed/total: 75/1027 https://lgbtqia.fandom.com/wiki/category:emerging_terminology\n",
      "processed/total: 76/1026 https://lgbtqia.fandom.com/wiki/aromantic_spectrum#lithromantic\n",
      "processed/total: 77/1025 https://lgbtqia.fandom.com/wiki/file:toric.png\n",
      "processed/total: 78/1029 https://lgbtqia.fandom.com/wiki/file:genderfae_flag.png\n",
      "processed/total: 79/1045 https://lgbtqia.fandom.com/wiki/drag\n",
      "processed/total: 80/1044 https://lgbtqia.fandom.com/wiki/daughters_of_bilitis\n",
      "processed/total: 81/1043 https://lgbtqia.fandom.com/wiki/heteromantic\n",
      "processed/total: 82/1046 https://lgbtqia.fandom.com/wiki/a?oldid=14363\n",
      "processed/total: 83/1049 https://lgbtqia.fandom.com/wiki/paragraph_175\n",
      "processed/total: 84/1048 https://lgbtqia.fandom.com/wiki/aporagender\n",
      "processed/total: 85/1047 https://lgbtqia.fandom.com/wiki/allosexual_aromantic\n",
      "processed/total: 86/1050 https://lgbtqia.fandom.com/wiki/abrosexual\n",
      "processed/total: 87/1055 https://lgbtqia.fandom.com/wiki/queerbaiting\n",
      "processed/total: 88/1054 https://lgbtqia.fandom.com/wiki/file:gay_flag_baker.svg\n",
      "processed/total: 89/1056 https://lgbtqia.fandom.com/wiki/gender_spectrum\n",
      "processed/total: 90/1055 https://lgbtqia.fandom.com/wiki/aegosexual\n",
      "processed/total: 91/1058 https://lgbtqia.fandom.com/wiki/file:aroaceflux.png\n",
      "processed/total: 92/1057 https://lgbtqia.fandom.com/wiki/file:bigender_flag.svg\n",
      "processed/total: 93/1056 https://lgbtqia.fandom.com/wiki/talk:affix?action=edit&redlink=1\n",
      "processed/total: 94/1055 https://lgbtqia.fandom.com/wiki/quoiromantic\n",
      "processed/total: 95/1054 https://lgbtqia.fandom.com/wiki/harvey_milk\n",
      "processed/total: 96/1053 https://lgbtqia.fandom.com/wiki/amab\n",
      "processed/total: 97/1052 https://lgbtqia.fandom.com/wiki/%22don%27t_say_gay%22\n",
      "processed/total: 98/1051 https://lgbtqia.fandom.com/wiki/christopher_street_liberation_day\n",
      "processed/total: 99/1050 https://lgbtqia.fandom.com/wiki/file:pulse_victims.jpg\n",
      "processed/total: 100/1049 https://lgbtqia.fandom.com/wiki/aromantic-spectrum_union_for_recognition,_education,_and_advocacy\n",
      "processed/total: 101/1048 https://lgbtqia.fandom.com/wiki/file:grayasexual.png\n",
      "processed/total: 102/1047 https://lgbtqia.fandom.com/wiki/autosexual\n",
      "processed/total: 103/1049 https://lgbtqia.fandom.com/wiki/user:karasuneth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <finalize object at 0x2b30ab53c60; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"b:\\Programas\\Programming\\Python\\Lib\\weakref.py\", line 588, in __call__\n",
      "    info = self._registry.pop(self, None)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed/total: 104/1048 https://lgbtqia.fandom.com/wiki/affixes\n",
      "processed/total: 105/1047 https://lgbtqia.fandom.com/wiki/bi-lesbian\n",
      "processed/total: 106/1049 https://lgbtqia.fandom.com/wiki/sapphic\n",
      "processed/total: 107/1048 https://lgbtqia.fandom.com/wiki/gender_roles\n",
      "processed/total: 108/1052 https://lgbtqia.fandom.com/wiki/category:articles_with_unsourced_information\n",
      "processed/total: 109/1230 https://lgbtqia.fandom.com/wiki/drag?action=history\n",
      "processed/total: 110/1237 https://lgbtqia.fandom.com/wiki/egogender\n",
      "processed/total: 111/1293 https://lgbtqia.fandom.com/wiki/multigender?action=history\n",
      "processed/total: 112/1292 https://lgbtqia.fandom.com/wiki/norm?action=purge\n",
      "processed/total: 113/1291 https://lgbtqia.fandom.com/wiki/file:twink_flag.svg\n",
      "processed/total: 114/1290 https://lgbtqia.fandom.com/wiki/multigender\n",
      "processed/total: 115/1289 https://lgbtqia.fandom.com/wiki/file:a-spec_main_flag.svg\n",
      "processed/total: 116/1288 https://lgbtqia.fandom.com/wiki/reciproromantic\n",
      "processed/total: 117/1287 https://lgbtqia.fandom.com/wiki/file:transmasc_flag.png\n",
      "processed/total: 118/1289 https://lgbtqia.fandom.com/wiki/a?diff=prev&oldid=14363\n",
      "processed/total: 119/1288 https://lgbtqia.fandom.com/wiki/file:rainbow_flag1.svg\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Process everything\n",
    "converts all links from sets into a single set to be processed.\n",
    "Each link that was not already processed is processed and added to the processed links.\n",
    "The processed link is removed from the unprocessed links.\n",
    "If new found links are not already in the processed links, they are added to the unprocessed links set.\n",
    "\"\"\"\n",
    "\n",
    "unprocessed_links = set()\n",
    "\n",
    "def process_all_links():\n",
    "    links_to_process = set()\n",
    "    for link in allHyperLinks.values():\n",
    "        links_to_process.update(link['hyperlinks'])\n",
    "    print(len(links_to_process))\n",
    "    # print_each(sorted(list(links_to_process)))\n",
    "    while links_to_process:\n",
    "        link = links_to_process.pop()\n",
    "        if link in allHyperLinks:\n",
    "            continue\n",
    "        soup = get_soup(link)\n",
    "        current_hyperlinks = set() if soup is None else get_hyperlinks(soup)    \n",
    "        allHyperLinks[link] = {'soup': soup, 'hyperlinks': current_hyperlinks}\n",
    "        links_to_process.update(current_hyperlinks - set(allHyperLinks.keys()))\n",
    "        \n",
    "        print(f'processed/total: {len(allHyperLinks)}/{len(links_to_process)}', link)\n",
    "\n",
    "process_all_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1}\n"
     ]
    }
   ],
   "source": [
    "print(set([1, 2, 3]) - set([2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_to_json(data, filename):\n",
    "    \"\"\"\n",
    "    Salva o dicionário como arquivo JSON, convertendo objetos BeautifulSoup para string\n",
    "    \"\"\"\n",
    "    def soup_to_str(obj):\n",
    "        if isinstance(obj, BeautifulSoup):\n",
    "            return str(obj)\n",
    "        return obj\n",
    "\n",
    "    processed_data = {}\n",
    "    for key, value in data.items():\n",
    "        processed_data[key] = {\n",
    "            'soup': str(value['soup']),  # Converte BeautifulSoup para string\n",
    "            'hyperlinks': list(value['hyperlinks'])  # Converte set para lista\n",
    "        }\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(processed_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Após process_all_links(), adicione:\n",
    "save_to_json(initial_processed_links, 'scraped_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Check items that are in all lists \"\"\"\n",
    "\n",
    "def get_common_links(all_links):\n",
    "    \"\"\" get common links \"\"\"\n",
    "    common_links = set(all_links[0])\n",
    "    for links in all_links[1:]:\n",
    "        common_links.intersection_update(links)\n",
    "    return common_links\n",
    "\n",
    "common_links = get_common_links(allHyperLinks)\n",
    "\n",
    "print_size(common_links, 'common links')\n",
    "\n",
    "print(common_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Filtering Links \"\"\"\n",
    "\n",
    "print('size:', len(allHyperLinks))\n",
    "allHyperLinks = dedupe_and_sort(allHyperLinks)\n",
    "print('size:', len(allHyperLinks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Second Iteration \"\"\"\n",
    "\n",
    "allHyperLinks += get_hyperlinks_from_list_of_links(allHyperLinks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('size:', len(allHyperLinks))\n",
    "filteredAllHyperLinks = dedupe_and_sort(allHyperLinks).copy()\n",
    "print('size:', len(allHyperLinks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" More filtering \"\"\"\n",
    "\n",
    "def link_404(link):\n",
    "    \"\"\" remove 404 links \"\"\"\n",
    "    page = requests.get(link)\n",
    "    return page.status_code == 404\n",
    "\n",
    "def link_question(link):\n",
    "    \"\"\" remove question links \"\"\"\n",
    "    return '?' in link\n",
    "\n",
    "def link_hashtag(link):\n",
    "    \"\"\" remove hashtag links \"\"\"\n",
    "    return '#' in link\n",
    "\n",
    "def filtering_links(links):\n",
    "    \"\"\" filtering links \"\"\"\n",
    "    for link in links:\n",
    "        print(link)\n",
    "        if link_question(link) or link_404(link) or link_hashtag(link):\n",
    "            print('removing:', link)\n",
    "            links.remove(link)\n",
    "    return links\n",
    "\n",
    "\n",
    "\n",
    "print_size(filteredAllHyperLinks)\n",
    "# filteredAllHyperLinks = filtering_links(filteredAllHyperLinks)\n",
    "print_size(filteredAllHyperLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexisting_pages = [\n",
    "    'https://lgbtqia.fandom.com/wiki/2-spirit',\n",
    "    'https://lgbtqia.fandom.com/wiki/ace_lesbian',\n",
    "    'https://lgbtqia.fandom.com/wiki/equality_act',\n",
    "    'https://lgbtqia.fandom.com/wiki/adonic',\n",
    "    'https://lgbtqia.fandom.com/wiki/equality_act_2010',\n",
    "]\n",
    "\n",
    "for link in unexisting_pages:\n",
    "    page = requests.get(link)\n",
    "    print(page.status_code)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
