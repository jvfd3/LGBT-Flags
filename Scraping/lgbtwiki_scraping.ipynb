{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Pip Install \"\"\"\n",
    "\n",
    "%pip install requests bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports \"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import unquote, urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Aux func \"\"\"\n",
    "\n",
    "def print_each(list_of_links):\n",
    "    \"\"\" print each \"\"\"\n",
    "    for link in list_of_links:\n",
    "        print(link)\n",
    "\n",
    "def print_size(list_of_links, link = ''):\n",
    "    \"\"\" print size \"\"\"\n",
    "    print('size:', '\\t', len(list_of_links), '\\t', link)\n",
    "\n",
    "def dedupe_and_sort(links):\n",
    "    \"\"\" filter and sort links \"\"\"\n",
    "    links = list(set(links)) # deduping\n",
    "    links.sort() # sorting\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Scraping \"\"\"\n",
    "\n",
    "base_link = 'https://lgbtqia.fandom.com/wiki/'\n",
    "\n",
    "links = ['', 'Special:AllPages', 'Special:AllPages?from=LGBTQA',\n",
    "         'Special:Categories', 'Category:Flags', 'Category:Stubs',]\n",
    "\n",
    "links = [base_link + link for link in links]\n",
    "\n",
    "allHyperLinks = {}\n",
    "\n",
    "\n",
    "def clean_found_hlinks(all_a):\n",
    "    # print(len(all_a))\n",
    "    current_hyperlinks = []\n",
    "    for link in all_a:\n",
    "        # print(link)\n",
    "        got_href = link.get('href')\n",
    "        if got_href is not None:\n",
    "            # print(got_href)\n",
    "            got_href = got_href.lstrip('/')\n",
    "            got_href = got_href.lower()\n",
    "            full_link = got_href\n",
    "            # print(got_href)\n",
    "            if got_href.startswith('wiki/'):\n",
    "                full_link = 'https://lgbtqia.fandom.com/' + got_href\n",
    "            if full_link.startswith(base_link):\n",
    "                # print(full_link)\n",
    "                current_hyperlinks.append(full_link)\n",
    "    filtered_links = dedupe_and_sort(current_hyperlinks)\n",
    "    return filtered_links\n",
    "\n",
    "def get_hyperlinks(url):\n",
    "    \"\"\" get hyperlinks \"\"\"\n",
    "    all_a = soup.find_all('a')\n",
    "    cleaned_hlinks = clean_found_hlinks(all_a)\n",
    "    return cleaned_hlinks\n",
    "\n",
    "def get_hyperlinks_from_list_of_links(links):\n",
    "    \"\"\" get hyperlinks from list of links \"\"\"\n",
    "    allHyperLinks = []\n",
    "    for link in links:\n",
    "        current_link_hyperlinks = get_hyperlinks(link)\n",
    "        print_size(current_link_hyperlinks, link)\n",
    "        allHyperLinks.append(current_link_hyperlinks)\n",
    "    return allHyperLinks\n",
    "\n",
    "allHyperLinks = get_hyperlinks_from_list_of_links(links)\n",
    "\n",
    "def get_soup(link):\n",
    "    \"\"\" parse link \"\"\"\n",
    "    page = requests.get(link)\n",
    "    if page.status_code != 200:\n",
    "        return []\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    return soup\n",
    "    \n",
    "    \n",
    "\n",
    "print('collected links once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Check items that are in all lists \"\"\"\n",
    "\n",
    "def get_common_links(all_links):\n",
    "    \"\"\" get common links \"\"\"\n",
    "    common_links = set(all_links[0])\n",
    "    for links in all_links[1:]:\n",
    "        common_links.intersection_update(links)\n",
    "    return common_links\n",
    "\n",
    "common_links = get_common_links(allHyperLinks)\n",
    "\n",
    "print_size(common_links, 'common links')\n",
    "\n",
    "print(common_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Filtering Links \"\"\"\n",
    "\n",
    "print('size:', len(allHyperLinks))\n",
    "allHyperLinks = dedupe_and_sort(allHyperLinks)\n",
    "print('size:', len(allHyperLinks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Second Iteration \"\"\"\n",
    "\n",
    "allHyperLinks += get_hyperlinks_from_list_of_links(allHyperLinks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('size:', len(allHyperLinks))\n",
    "filteredAllHyperLinks = dedupe_and_sort(allHyperLinks).copy()\n",
    "print('size:', len(allHyperLinks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" More filtering \"\"\"\n",
    "\n",
    "def link_404(link):\n",
    "    \"\"\" remove 404 links \"\"\"\n",
    "    page = requests.get(link)\n",
    "    return page.status_code == 404\n",
    "\n",
    "def link_question(link):\n",
    "    \"\"\" remove question links \"\"\"\n",
    "    return '?' in link\n",
    "\n",
    "def link_hashtag(link):\n",
    "    \"\"\" remove hashtag links \"\"\"\n",
    "    return '#' in link\n",
    "\n",
    "def filtering_links(links):\n",
    "    \"\"\" filtering links \"\"\"\n",
    "    for link in links:\n",
    "        print(link)\n",
    "        if link_question(link) or link_404(link) or link_hashtag(link):\n",
    "            print('removing:', link)\n",
    "            links.remove(link)\n",
    "    return links\n",
    "\n",
    "\n",
    "\n",
    "print_size(filteredAllHyperLinks)\n",
    "# filteredAllHyperLinks = filtering_links(filteredAllHyperLinks)\n",
    "print_size(filteredAllHyperLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexisting_pages = [\n",
    "    'https://lgbtqia.fandom.com/wiki/2-spirit',\n",
    "    'https://lgbtqia.fandom.com/wiki/ace_lesbian',\n",
    "    'https://lgbtqia.fandom.com/wiki/equality_act',\n",
    "    'https://lgbtqia.fandom.com/wiki/adonic',\n",
    "    'https://lgbtqia.fandom.com/wiki/equality_act_2010',\n",
    "]\n",
    "\n",
    "for link in unexisting_pages:\n",
    "    page = requests.get(link)\n",
    "    print(page.status_code)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
